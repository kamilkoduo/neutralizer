{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.metrics import functional as FM\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os.path import basename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper\n",
    "def show_in_row(list_of_images: list, titles: list = None, disable_ticks: bool = False):\n",
    "    count = len(list_of_images)\n",
    "    for idx in range(count):\n",
    "        subplot = plt.subplot(1, count, idx+1)\n",
    "        if titles is not None:\n",
    "            subplot.set_title(titles[idx])\n",
    "      \n",
    "        img = list_of_images[idx]\n",
    "        cmap = 'gray' if (len(img.shape) == 2 or img.shape[2] == 1) else None\n",
    "        subplot.imshow(img, cmap=cmap)\n",
    "        if disable_ticks:\n",
    "            plt.xticks([]), plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "# Data\n",
    "\n",
    "DATA_RAW_ROOT = '../data/raw'\n",
    "\n",
    "TEST_SIZE = 0.1\n",
    "TRAIN_BATCH = 64\n",
    "VALID_BATCH = 1024\n",
    "IMG_SIZE = (256, 256)\n",
    "\n",
    "# todo: ? add randomized augmentation as transform for train samples ?\n",
    "\n",
    "dataset_transform = transforms.Compose([\n",
    "            transforms.Resize(IMG_SIZE),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,)),\n",
    "        ])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.1059, -0.1059, -0.0902,  ..., -0.0039, -0.0196, -0.0039],\n",
       "          [-0.1451, -0.0824, -0.1608,  ..., -0.0353, -0.0745,  0.0275],\n",
       "          [-0.1451, -0.1059, -0.0824,  ..., -0.0196,  0.0275,  0.0275],\n",
       "          ...,\n",
       "          [-0.4980, -0.5137, -0.5529,  ..., -0.4275, -0.4353, -0.4667],\n",
       "          [-0.5373, -0.5686, -0.5529,  ..., -0.4039, -0.4588, -0.4275],\n",
       "          [-0.4745, -0.5843, -0.5451,  ..., -0.4588, -0.4588, -0.3961]]]),\n",
       " {'path': PosixPath('../data/raw/jaffe/TM.HA3.182.tiff'),\n",
       "  'exp': <Expression.HAPPY: 'HA'>,\n",
       "  'iden': 'TM'})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "import enum\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "\n",
    "RAW_JAFFE_DATA_DIR = Path('../data/raw/jaffe')\n",
    "\n",
    "class Expression(enum.Enum):\n",
    "    NEUTRAL  = 'NE'\n",
    "    ANGRY    = 'AN'\n",
    "    DISGUST  = 'DI'\n",
    "    FEAR     = 'FE'\n",
    "    HAPPY    = 'HA'\n",
    "    SAD      = 'SA'\n",
    "    SURPRISE = 'SU'\n",
    "    \n",
    "    \n",
    "ExpEnc = {exp:idx for idx, exp in enumerate(Expression)}\n",
    "ExpDec = {idx:exp for idx, exp in enumerate(Expression)}\n",
    "\n",
    "\n",
    "\n",
    "class JAFFEDataset(Dataset):\n",
    "    def __init__(self, data_dir=RAW_JAFFE_DATA_DIR, expression=None):\n",
    "        \"\"\"\n",
    "        :param data_dir (Path)         : Path to images\n",
    "        :param expression (Expression) : Enum member, expression label\n",
    "        \"\"\"\n",
    "        \n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.samples = self.build_dict()\n",
    "        \n",
    "        self.transform = dataset_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        desc = self.samples[idx]\n",
    "        image_path = desc['path']\n",
    "        image = Image.fromarray(io.imread(image_path, as_gray=True))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return (image, desc)\n",
    "    \n",
    "    def build_dict(self):\n",
    "        samples = []\n",
    "        for entry in self.data_dir.iterdir():\n",
    "            tokens = entry.name.split('.')\n",
    "            if tokens[-1] != 'tiff':\n",
    "                continue\n",
    "            \n",
    "            exp = tokens[1][:2]\n",
    "            iden = tokens[0]\n",
    "            \n",
    "            samples.append({\n",
    "                'path': entry,\n",
    "                'exp' : Expression(exp),\n",
    "                'iden': iden,\n",
    "            })\n",
    "            \n",
    "        return samples\n",
    "    \n",
    "    def exp_split(self, test_size=0.1, random_state=42):\n",
    "        exps = []\n",
    "        for s in self.samples:\n",
    "            exps.append(s['exp'])\n",
    "        \n",
    "        \n",
    "        splitter = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "        splits = splitter.split(X=np.arange(len(exps), dtype=np.int), y=[ExpEnc[e] for e in exps])\n",
    "        \n",
    "        train_idx, test_idx = next(splits)\n",
    "        \n",
    "        train_ds = Subset(self, train_idx)\n",
    "        test_ds = Subset(self, test_idx)\n",
    "        \n",
    "        return train_ds, test_ds\n",
    "        \n",
    "            \n",
    "# test\n",
    "jaffe = JAFFEDataset()\n",
    "samples = jaffe.samples\n",
    "# print('\\n'.join([f'{s}' for s in samples]))\n",
    "one,two = jaffe.exp_split()\n",
    "\n",
    "jaffe[0]\n",
    "one[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAFFE data found\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not an iterator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-fac3bacca37a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not an iterator"
     ]
    }
   ],
   "source": [
    "class JAFFEDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size=32):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        if not RAW_JAFFE_DATA_DIR.exists():\n",
    "            print('JAFFE data not found')\n",
    "        else:\n",
    "            print('JAFFE data found')\n",
    "    \n",
    "    def setup(self, scenario = None, stage=None):\n",
    "        self.dataset = JAFFEDataset()\n",
    "        \n",
    "        if scenario == 'exp' or scenario is None:\n",
    "            self.jaffe_train, self.jaffe_test = self.dataset.exp_split()\n",
    "            \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.jaffe_train, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "#     def val_dataloader(self):\n",
    "#         return DataLoader(self.mnist_val, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.jaffe_test, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "    \n",
    "dm = JAFFEDataModule()\n",
    "dm.prepare_data()\n",
    "dm.setup()\n",
    "dl = dm.train_dataloader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
